"""
Optimized Stochastic Discrete Ricci Flow (SDRF) rewiring for BRIDGE
===================================================================
This module implements an optimized version of the SDRF algorithm from:

  "Understanding Overâ€‘Squashing and Bottlenecks on Graphs via Curvature"
  Michael Topping, et al., ICLR 2022
  https://arxiv.org/pdf/2111.14522

Key optimizations:
- Vectorized curvature computation using sparse matrix operations
- Batched edge operations to minimize graph reconstruction
- GPU-accelerated triangle and square counting
- Efficient sparse adjacency matrix updates
"""

from __future__ import annotations

import torch
import torch.sparse as sparse
import dgl
from typing import Tuple, Optional, Dict
import numpy as np

from numba import cuda, float32, int32, void
from numba.cuda import grid, atomic
from typing import Tuple, Optional

from dataclasses import dataclass


# Disable Numba performance warnings globally
import os
os.environ['NUMBA_DISABLE_PERFORMANCE_WARNINGS'] = '1'

import warnings
from numba.core.errors import NumbaPerformanceWarning

warnings.filterwarnings('ignore', category=NumbaPerformanceWarning)


class OptimizedSDRF:
    """Optimized SDRF rewiring using sparse matrix operations."""
    
    def __init__(
        self,
        tau: float = 10.0,
        n_iterations: int = 200,
        c_plus: float = 30.0,
        symmetric: bool = True,
        device: str | torch.device = "cuda",
        verbose: bool = False,
    ):
        self.tau = tau
        self.n_iterations = n_iterations
        self.c_plus = c_plus
        self.symmetric = symmetric
        self.device = torch.device(device)
        self.verbose = verbose
        
    def rewire(self, g_in: dgl.DGLGraph) -> dgl.DGLGraph:
        """Rewire graph using optimized SDRF."""
        # Prepare graph
        g = dgl.to_simple(g_in.cpu())
        if self.symmetric:
            g = dgl.to_bidirected(g, copy_ndata=True)
        g = g.to(self.device)
        
        n_nodes = g.num_nodes()
        
        # Convert to sparse adjacency matrix for efficient operations
        src, dst = g.edges()
        adj = self._build_sparse_adj(src, dst, n_nodes)
        
        for it in range(self.n_iterations):
            # Vectorized curvature computation
            curv, edge_data = self._compute_all_curvatures_vectorized(adj, src, dst)
            
            min_c, min_idx = torch.min(curv, dim=0)
            if min_c >= 0:
                if self.verbose:
                    print(f"[SDRF] Terminating at iter {it}: no negative curvature.")
                break
                
            # Get edge with minimum curvature
            u = src[min_idx].item()
            v = dst[min_idx].item()
            
            if self.verbose and (it % 20 == 0):
                print(f"[SDRF] iter={it}   min curvature={min_c:.4f}  edge=({u},{v})")
            
            # Find candidate edges efficiently
            cand_edges, cand_scores = self._find_candidates_vectorized(
                adj, u, v, min_c.item(), edge_data
            )
            
            if len(cand_edges) == 0:
                if self.verbose:
                    print("[SDRF] No candidate edge found; terminating early.")
                break
            
            # Sample edge to add
            logits = torch.tensor(cand_scores, dtype=torch.float32, device=self.device)
            probs = torch.softmax(logits / self.tau, dim=0)
            choice = torch.multinomial(probs, 1).item()
            k_add, l_add = cand_edges[choice]
            
            # Update adjacency matrix
            adj = self._add_edge_to_sparse(adj, k_add, l_add, n_nodes)
            if self.symmetric:
                adj = self._add_edge_to_sparse(adj, l_add, k_add, n_nodes)
            
            # Optional removal of high curvature edge
            max_c, max_idx = torch.max(curv, dim=0)
            if max_c > self.c_plus:
                rm_u = src[max_idx].item()
                rm_v = dst[max_idx].item()
                adj = self._remove_edge_from_sparse(adj, rm_u, rm_v, n_nodes)
                if self.symmetric:
                    adj = self._remove_edge_from_sparse(adj, rm_v, rm_u, n_nodes)
            
            # Update edge list for next iteration
            src, dst = self._sparse_to_edges(adj)
        
        # Convert back to DGL graph
        g_out = dgl.graph((src.cpu(), dst.cpu()), num_nodes=n_nodes)
        g_out = g_out.to(self.device)
        
        # Copy node features if any
        for key, value in g_in.ndata.items():
            g_out.ndata[key] = value.to(self.device)
            
        return g_out
    
    def _build_sparse_adj(
        self, src: torch.Tensor, dst: torch.Tensor, n_nodes: int
    ) -> torch.sparse.FloatTensor:
        """Build sparse adjacency matrix."""
        indices = torch.stack([src, dst])
        values = torch.ones(src.shape[0], device=self.device)
        adj = torch.sparse_coo_tensor(
            indices, values, (n_nodes, n_nodes), device=self.device
        )
        return adj
    
    def _sparse_to_edges(self, adj: torch.sparse.FloatTensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """Extract edge list from sparse adjacency matrix."""
        indices = adj.coalesce().indices()
        return indices[0], indices[1]
    
    def _compute_all_curvatures_vectorized(
        self, adj: torch.sparse.FloatTensor, src: torch.Tensor, dst: torch.Tensor
    ) -> Tuple[torch.Tensor, dict]:
        """Compute curvatures for all edges using vectorized operations."""
        n_nodes = adj.shape[0]
        n_edges = src.shape[0]
        
        # Compute degrees efficiently
        deg = torch.sparse.sum(adj, dim=1).to_dense()
        
        # Vectorized triangle counting using matrix multiplication
        # A^2 gives paths of length 2; diagonal of A @ A^2 gives triangles
        adj_dense = adj.to_dense()  # For small graphs, dense can be faster
        adj2 = torch.sparse.mm(adj, adj.t())
        
        # Count triangles for each edge
        triangles = torch.zeros(n_edges, device=self.device)
        for i in range(n_edges):
            u, v = src[i].item(), dst[i].item()
            triangles[i] = adj2[u, v].item()
        
        # Vectorized square counting
        squares_u = torch.zeros(n_edges, device=self.device)
        squares_v = torch.zeros(n_edges, device=self.device)
        
        # Batch compute for efficiency
        batch_size = min(1000, n_edges)
        for i in range(0, n_edges, batch_size):
            batch_end = min(i + batch_size, n_edges)
            batch_src = src[i:batch_end]
            batch_dst = dst[i:batch_end]
            
            for j, (u, v) in enumerate(zip(batch_src, batch_dst)):
                u_idx, v_idx = u.item(), v.item()
                
                # Neighbors of u (excluding v)
                neigh_u = adj_dense[u_idx].nonzero().squeeze(-1)
                neigh_u = neigh_u[neigh_u != v_idx]
                
                # Neighbors of v (excluding u)
                neigh_v = adj_dense[v_idx].nonzero().squeeze(-1)
                neigh_v = neigh_v[neigh_v != u_idx]
                
                # Count squares efficiently
                if len(neigh_u) > 0 and len(neigh_v) > 0:
                    # Check which neighbors of u connect to neighbors of v
                    connections = adj_dense[neigh_u][:, neigh_v].sum(dim=1)
                    squares_u[i + j] = (connections > 0).sum().item()
                    
                    # Check which neighbors of v connect to neighbors of u
                    connections = adj_dense[neigh_v][:, neigh_u].sum(dim=1)
                    squares_v[i + j] = (connections > 0).sum().item()
        
        # Compute curvatures vectorized
        deg_src = deg[src]
        deg_dst = deg[dst]
        
        # Handle edge cases
        valid_mask = (deg_src > 1) & (deg_dst > 1)
        curv = torch.zeros(n_edges, device=self.device)
        
        # Vectorized computation for valid edges
        deg_max = torch.maximum(deg_src[valid_mask], deg_dst[valid_mask])
        deg_min = torch.minimum(deg_src[valid_mask], deg_dst[valid_mask])
        
        gamma_max = torch.maximum(
            torch.maximum(squares_u[valid_mask], squares_v[valid_mask]),
            torch.ones_like(squares_u[valid_mask])
        )
        
        term_tri = (
            2.0 * triangles[valid_mask] / deg_max + 
            triangles[valid_mask] / deg_min
        )
        term_sqr = (
            (squares_u[valid_mask] + squares_v[valid_mask]) / 
            (gamma_max * deg_max)
        )
        
        curv[valid_mask] = (
            2.0 / deg_src[valid_mask] + 
            2.0 / deg_dst[valid_mask] - 
            2.0 + term_tri + term_sqr
        )
        
        edge_data = {
            'triangles': triangles,
            'squares_u': squares_u,
            'squares_v': squares_v,
            'degrees': deg,
            'adj_dense': adj_dense
        }
        
        return curv, edge_data
    
    def _find_candidates_vectorized(
        self, adj: torch.sparse.FloatTensor, u: int, v: int, 
        base_c: float, edge_data: dict
    ) -> Tuple[list, list]:
        """Find candidate edges using vectorized operations."""
        adj_dense = edge_data['adj_dense']
        deg = edge_data['degrees']
        
        # Get neighbors efficiently
        neigh_u = adj_dense[u].nonzero().squeeze(-1)
        neigh_u = neigh_u[neigh_u != v]
        
        neigh_v = adj_dense[v].nonzero().squeeze(-1)
        neigh_v = neigh_v[neigh_v != u]
        
        if len(neigh_u) == 0 or len(neigh_v) == 0:
            return [], []
        
        # Vectorized candidate finding
        # Create mesh grid of all possible (k, l) pairs
        k_indices, l_indices = torch.meshgrid(neigh_u, neigh_v, indexing='ij')
        k_flat = k_indices.flatten()
        l_flat = l_indices.flatten()
        
        # Check which pairs are not connected
        not_connected = adj_dense[k_flat, l_flat] == 0
        
        # Filter valid candidates
        valid_k = k_flat[not_connected]
        valid_l = l_flat[not_connected]
        
        if len(valid_k) == 0:
            return [], []
        
        # Compute scores vectorized
        deg_u = deg[u].item()
        deg_v = deg[v].item()
        imp = 2.0 / max(deg_u, deg_v) + 1.0 / min(deg_u, deg_v)
        
        cand_edges = [(k.item(), l.item()) for k, l in zip(valid_k, valid_l)]
        cand_scores = [base_c + imp] * len(cand_edges)
        
        return cand_edges, cand_scores
    
    def _add_edge_to_sparse(
        self, adj: torch.sparse.FloatTensor, u: int, v: int, n_nodes: int
    ) -> torch.sparse.FloatTensor:
        """Add edge to sparse adjacency matrix."""
        indices = adj.coalesce().indices()
        values = adj.coalesce().values()
        
        # Add new edge
        new_indices = torch.cat([indices, torch.tensor([[u], [v]], device=self.device)], dim=1)
        new_values = torch.cat([values, torch.ones(1, device=self.device)])
        
        # Create new sparse tensor
        new_adj = torch.sparse_coo_tensor(
            new_indices, new_values, (n_nodes, n_nodes), device=self.device
        ).coalesce()
        
        return new_adj
    
    def _remove_edge_from_sparse(
        self, adj: torch.sparse.FloatTensor, u: int, v: int, n_nodes: int
    ) -> torch.sparse.FloatTensor:
        """Remove edge from sparse adjacency matrix."""
        indices = adj.coalesce().indices()
        values = adj.coalesce().values()
        
        # Find edge to remove
        edge_mask = ~((indices[0] == u) & (indices[1] == v))
        
        # Filter out the edge
        new_indices = indices[:, edge_mask]
        new_values = values[edge_mask]
        
        # Create new sparse tensor
        new_adj = torch.sparse_coo_tensor(
            new_indices, new_values, (n_nodes, n_nodes), device=self.device
        ).coalesce()
        
        return new_adj


def sdrf_rewire_optimized(
    g_in: dgl.DGLGraph,
    tau: float = 10.0,
    n_iterations: int = 200,
    c_plus: float = 30.0,
    symmetric: bool = True,
    device: str | torch.device = "cuda",
    verbose: bool = False,
) -> dgl.DGLGraph:
    """
    Optimized SDRF rewiring function with same interface as original.
    
    This version uses:
    - Vectorized curvature computation
    - Sparse matrix operations for efficiency
    - Batched edge operations
    - GPU acceleration throughout
    
    Parameters
    ----------
    g_in : dgl.DGLGraph
        Input graph (*undirected* preferred).
    tau : float
        Softmax temperature for edge sampling.
    n_iterations : int
        Maximum SDRF iterations.
    c_plus : float
        Positive curvature threshold.
    symmetric : bool
        Keep graph undirected/bidirected.
    device : str or torch.device
        Computation device.
    verbose : bool
        Print progress information.
        
    Returns
    -------
    dgl.DGLGraph
        Rewired graph.
    """
    optimizer = OptimizedSDRF(
        tau=tau,
        n_iterations=n_iterations,
        c_plus=c_plus,
        symmetric=symmetric,
        device=device,
        verbose=verbose
    )
    return optimizer.rewire(g_in)


# Additional optimization: parallel batch processing for multiple graphs
class BatchedSDRF:
    """Process multiple graphs in parallel for even better efficiency."""
    
    def __init__(self, **kwargs):
        self.sdrf_params = kwargs
        
    def rewire_batch(self, graphs: list[dgl.DGLGraph]) -> list[dgl.DGLGraph]:
        """
        Rewire multiple graphs in parallel using multi-GPU if available.
        
        Parameters
        ----------
        graphs : list[dgl.DGLGraph]
            List of input graphs.
            
        Returns
        -------
        list[dgl.DGLGraph]
            List of rewired graphs.
        """
        # Check available GPUs
        n_gpus = torch.cuda.device_count()
        if n_gpus > 1 and len(graphs) > 1:
            # Distribute graphs across GPUs
            import concurrent.futures
            
            def process_on_gpu(g, gpu_id):
                device = f'cuda:{gpu_id}'
                params = {**self.sdrf_params, 'device': device}
                return sdrf_rewire_optimized(g, **params)
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=n_gpus) as executor:
                futures = []
                for i, g in enumerate(graphs):
                    gpu_id = i % n_gpus
                    futures.append(executor.submit(process_on_gpu, g, gpu_id))
                
                results = [f.result() for f in futures]
                return results
        else:
            # Process sequentially
            return [sdrf_rewire_optimized(g, **self.sdrf_params) for g in graphs]


# Benchmark utilities
def benchmark_sdrf(g: dgl.DGLGraph, n_runs: int = 5):
    """Benchmark the optimized SDRF implementation."""
    import time
    
    times = []
    for _ in range(n_runs):
        start = time.time()
        _ = sdrf_rewire_optimized(g, n_iterations=50, verbose=False)
        times.append(time.time() - start)
    
    print(f"Average time over {n_runs} runs: {np.mean(times):.3f}s Â± {np.std(times):.3f}s")
    return times


"""
Numba CUDA-optimized Stochastic Discrete Ricci Flow (SDRF) rewiring
===================================================================
This module implements SDRF with custom CUDA kernels using Numba for 
maximum performance on GPU.

Key optimizations:
- Custom CUDA kernels for triangle and square counting
- Parallel curvature computation across all edges
- Efficient sparse matrix operations on GPU
- Minimized memory transfers between host and device
"""





# CUDA kernel for counting triangles for all edges in parallel
@cuda.jit
def count_triangles_kernel(
    row_ptr: cuda.devicearray,
    col_idx: cuda.devicearray,
    edges_src: cuda.devicearray,
    edges_dst: cuda.devicearray,
    triangles: cuda.devicearray,
    n_edges: int
):
    """CUDA kernel to count triangles for each edge."""
    idx = grid(1)
    if idx >= n_edges:
        return
    
    u = edges_src[idx]
    v = edges_dst[idx]
    
    # Find neighbors of u
    u_start = row_ptr[u]
    u_end = row_ptr[u + 1]
    
    # Find neighbors of v
    v_start = row_ptr[v]
    v_end = row_ptr[v + 1]
    
    # Count common neighbors (triangles)
    count = 0
    i, j = u_start, v_start
    
    # Two-pointer intersection
    while i < u_end and j < v_end:
        if col_idx[i] == col_idx[j]:
            count += 1
            i += 1
            j += 1
        elif col_idx[i] < col_idx[j]:
            i += 1
        else:
            j += 1
    
    triangles[idx] = count


# CUDA kernel for counting squares (4-cycles)
@cuda.jit
def count_squares_kernel(
    row_ptr: cuda.devicearray,
    col_idx: cuda.devicearray,
    edges_src: cuda.devicearray,
    edges_dst: cuda.devicearray,
    squares_u: cuda.devicearray,
    squares_v: cuda.devicearray,
    n_edges: int
):
    """CUDA kernel to count squares for each edge."""
    idx = grid(1)
    if idx >= n_edges:
        return
    
    u = edges_src[idx]
    v = edges_dst[idx]
    
    # Count squares from u's perspective
    u_start = row_ptr[u]
    u_end = row_ptr[u + 1]
    v_start = row_ptr[v]
    v_end = row_ptr[v + 1]
    
    count_u = 0
    # For each neighbor k of u (k != v)
    for i in range(u_start, u_end):
        k = col_idx[i]
        if k == v:
            continue
            
        # Check if k connects to any neighbor of v (excluding u)
        k_start = row_ptr[k]
        k_end = row_ptr[k + 1]
        
        for j in range(v_start, v_end):
            l = col_idx[j]
            if l == u:
                continue
                
            # Binary search for l in k's neighbors
            left, right = k_start, k_end - 1
            found = False
            while left <= right:
                mid = (left + right) // 2
                if col_idx[mid] == l:
                    found = True
                    break
                elif col_idx[mid] < l:
                    left = mid + 1
                else:
                    right = mid - 1
            
            if found:
                count_u = 1  # At least one square exists
                break
        
        if count_u > 0:
            count_u += 1  # Count this k
    
    # Similar for v's perspective
    count_v = 0
    for i in range(v_start, v_end):
        l = col_idx[i]
        if l == u:
            continue
            
        l_start = row_ptr[l]
        l_end = row_ptr[l + 1]
        
        for j in range(u_start, u_end):
            k = col_idx[j]
            if k == v:
                continue
                
            # Binary search for k in l's neighbors
            left, right = l_start, l_end - 1
            found = False
            while left <= right:
                mid = (left + right) // 2
                if col_idx[mid] == k:
                    found = True
                    break
                elif col_idx[mid] < k:
                    left = mid + 1
                else:
                    right = mid - 1
            
            if found:
                count_v = 1
                break
        
        if count_v > 0:
            count_v += 1
    
    squares_u[idx] = count_u
    squares_v[idx] = count_v


# CUDA kernel for computing balanced Forman curvature
@cuda.jit
def compute_curvature_kernel(
    degrees: cuda.devicearray,
    edges_src: cuda.devicearray,
    edges_dst: cuda.devicearray,
    triangles: cuda.devicearray,
    squares_u: cuda.devicearray,
    squares_v: cuda.devicearray,
    curvatures: cuda.devicearray,
    n_edges: int
):
    """CUDA kernel to compute curvature for all edges."""
    idx = grid(1)
    if idx >= n_edges:
        return
    
    u = edges_src[idx]
    v = edges_dst[idx]
    deg_u = degrees[u]
    deg_v = degrees[v]
    
    if deg_u <= 1 or deg_v <= 1:
        curvatures[idx] = 0.0
        return
    
    tri = triangles[idx]
    sq_u = squares_u[idx]
    sq_v = squares_v[idx]
    
    deg_max = max(deg_u, deg_v)
    deg_min = min(deg_u, deg_v)
    gamma_max = max(max(sq_u, sq_v), 1)
    
    term_tri = (2.0 * tri) / deg_max + tri / deg_min
    term_sqr = (sq_u + sq_v) / (gamma_max * deg_max)
    
    curvatures[idx] = 2.0 / deg_u + 2.0 / deg_v - 2.0 + term_tri + term_sqr


# CUDA kernel for finding candidate edges
@cuda.jit
def find_candidates_kernel(
    row_ptr: cuda.devicearray,
    col_idx: cuda.devicearray,
    u: int,
    v: int,
    deg_u: int,
    deg_v: int,
    base_curvature: float,
    candidates_k: cuda.devicearray,
    candidates_l: cuda.devicearray,
    candidates_score: cuda.devicearray,
    candidate_count: cuda.devicearray
):
    """CUDA kernel to find candidate edges in parallel."""
    tid = grid(1)
    
    u_start = row_ptr[u]
    u_end = row_ptr[u + 1]
    v_start = row_ptr[v]
    v_end = row_ptr[v + 1]
    
    u_size = u_end - u_start
    v_size = v_end - v_start
    
    if tid >= u_size * v_size:
        return
    
    # Map thread ID to (k, l) pair
    k_idx = tid // v_size
    l_idx = tid % v_size
    
    k = col_idx[u_start + k_idx]
    l = col_idx[v_start + l_idx]
    
    if k == v or l == u:
        return
    
    # Check if edge (k, l) exists
    k_start = row_ptr[k]
    k_end = row_ptr[k + 1]
    
    # Binary search for l in k's neighbors
    left, right = k_start, k_end - 1
    exists = False
    while left <= right:
        mid = (left + right) // 2
        if col_idx[mid] == l:
            exists = True
            break
        elif col_idx[mid] < l:
            left = mid + 1
        else:
            right = mid - 1
    
    if not exists:
        # Calculate improvement
        deg_max = max(deg_u, deg_v)
        deg_min = min(deg_u, deg_v)
        improvement = 2.0 / deg_max + 1.0 / deg_min
        score = base_curvature + improvement
        
        # Atomically add to candidates
        idx = cuda.atomic.add(candidate_count, 0, 1)
        if idx < candidates_k.shape[0]:
            candidates_k[idx] = k
            candidates_l[idx] = l
            candidates_score[idx] = score


class NumbaOptimizedSDRF:
    """SDRF implementation with Numba CUDA kernels."""
    
    def __init__(
        self,
        tau: float = 10.0,
        n_iterations: int = 200,
        c_plus: float = 30.0,
        symmetric: bool = True,
        device: str | torch.device = "cuda",
        verbose: bool = False,
        threads_per_block: int = 256
    ):
        self.tau = tau
        self.n_iterations = n_iterations
        self.c_plus = c_plus
        self.symmetric = symmetric
        self.device = torch.device(device)
        self.verbose = verbose
        self.threads_per_block = threads_per_block
        
        if not torch.cuda.is_available():
            raise RuntimeError("CUDA is required for Numba-optimized SDRF")
    
    def _to_csr(self, src: torch.Tensor, dst: torch.Tensor, n_nodes: int):
        """Convert edge list to CSR format for efficient GPU operations."""
        # Sort edges by source node
        src_np = src#.cpu().numpy()
        dst_np = dst#.cpu().numpy()
        
        # Create CSR representation
        row_ptr = np.zeros(n_nodes + 1, dtype=np.int32)
        
        # Count edges per node
        for s in src_np:
            row_ptr[s + 1] += 1
        
        # Cumulative sum
        for i in range(1, n_nodes + 1):
            row_ptr[i] += row_ptr[i - 1]
        
        # Fill column indices
        col_idx = np.zeros(len(src_np), dtype=np.int32)
        edge_pos = row_ptr[:-1].copy()
        
        for s, d in zip(src_np, dst_np):
            col_idx[edge_pos[s]] = d
            edge_pos[s] += 1
        
        # Sort neighbors for each node (for binary search)
        for i in range(n_nodes):
            start, end = row_ptr[i], row_ptr[i + 1]
            col_idx[start:end].sort()
        
        return row_ptr, col_idx
    
    def rewire(self, g_in: dgl.DGLGraph) -> dgl.DGLGraph:
        """Rewire graph using Numba CUDA kernels."""
        # Prepare graph
        g = dgl.to_simple(g_in.cpu())
        if self.symmetric:
            g = dgl.to_bidirected(g, copy_ndata=True)
        
        n_nodes = g.num_nodes()
        src, dst = g.edges()
        
        # Track edges as lists for dynamic updates
        edge_list = list(zip(src.tolist(), dst.tolist()))
        edge_set = set(edge_list)
        
        for it in range(self.n_iterations):
            # Convert current edges to GPU arrays
            n_edges = len(edge_list)
            edges_src = np.array([e[0] for e in edge_list], dtype=np.int32)
            edges_dst = np.array([e[1] for e in edge_list], dtype=np.int32)
            
            # Convert to CSR format
            row_ptr, col_idx = self._to_csr(edges_src, edges_dst, n_nodes)
            
            # Allocate GPU memory
            d_row_ptr = cuda.to_device(row_ptr)
            d_col_idx = cuda.to_device(col_idx)
            d_edges_src = cuda.to_device(edges_src)
            d_edges_dst = cuda.to_device(edges_dst)
            
            # Compute degrees
            degrees = np.zeros(n_nodes, dtype=np.int32)
            for i in range(n_nodes):
                degrees[i] = row_ptr[i + 1] - row_ptr[i]
            d_degrees = cuda.to_device(degrees)
            
            # Allocate output arrays
            d_triangles = cuda.device_array(n_edges, dtype=np.int32)
            d_squares_u = cuda.device_array(n_edges, dtype=np.int32)
            d_squares_v = cuda.device_array(n_edges, dtype=np.int32)
            d_curvatures = cuda.device_array(n_edges, dtype=np.float32)
            
            # Launch kernels
            blocks = (n_edges + self.threads_per_block - 1) // self.threads_per_block
            
            # Count triangles
            count_triangles_kernel[blocks, self.threads_per_block](
                d_row_ptr, d_col_idx, d_edges_src, d_edges_dst,
                d_triangles, n_edges
            )
            
            # Count squares
            count_squares_kernel[blocks, self.threads_per_block](
                d_row_ptr, d_col_idx, d_edges_src, d_edges_dst,
                d_squares_u, d_squares_v, n_edges
            )
            
            # Compute curvatures
            compute_curvature_kernel[blocks, self.threads_per_block](
                d_degrees, d_edges_src, d_edges_dst,
                d_triangles, d_squares_u, d_squares_v,
                d_curvatures, n_edges
            )
            
            # Copy curvatures back to CPU
            curvatures = d_curvatures.copy_to_host()
            
            # Find minimum curvature edge
            min_idx = np.argmin(curvatures)
            min_c = curvatures[min_idx]
            
            if min_c >= 0:
                if self.verbose:
                    print(f"[SDRF] Terminating at iter {it}: no negative curvature.")
                break
            
            u = edges_src[min_idx]
            v = edges_dst[min_idx]
            
            if self.verbose and (it % 20 == 0):
                print(f"[SDRF] iter={it}   min curvature={min_c:.4f}  edge=({u},{v})")
            
            # Find candidates
            max_candidates = degrees[u] * degrees[v]
            d_candidates_k = cuda.device_array((max_candidates,), dtype=np.int32)
            d_candidates_l = cuda.device_array((max_candidates,), dtype=np.int32)
            d_candidates_score = cuda.device_array((max_candidates,), dtype=np.float32)
            d_candidate_count = cuda.device_array((1,), dtype=np.int32)
            d_candidate_count[0] = 0
            
            # Launch candidate finding kernel
            blocks = (max_candidates + self.threads_per_block - 1) // self.threads_per_block
            find_candidates_kernel[blocks, self.threads_per_block](
                d_row_ptr, d_col_idx, u, v, degrees[u], degrees[v], min_c,
                d_candidates_k, d_candidates_l, d_candidates_score,
                d_candidate_count
            )
            
            # Get candidates
            n_candidates = d_candidate_count.copy_to_host()[0]
            if n_candidates == 0:
                if self.verbose:
                    print("[SDRF] No candidate edges found.")
                break
            
            candidates_k = d_candidates_k[:n_candidates].copy_to_host()
            candidates_l = d_candidates_l[:n_candidates].copy_to_host()
            candidates_score = d_candidates_score[:n_candidates].copy_to_host()
            
            # Sample edge using softmax
            logits = torch.tensor(candidates_score, dtype=torch.float32)
            probs = torch.softmax(logits / self.tau, dim=0)
            choice = torch.multinomial(probs, 1).item()
            
            k_add = candidates_k[choice]
            l_add = candidates_l[choice]
            
            # Add edge
            edge_list.append((k_add, l_add))
            
            edge_set.add((k_add, l_add))
            if self.symmetric:
                edge_list.append((l_add, k_add))
                edge_set.add((l_add, k_add))
            
            # Optional removal
            max_idx = np.argmax(curvatures)
            max_c = curvatures[max_idx]
            
            if max_c > self.c_plus:
                rm_u = edges_src[max_idx]
                rm_v = edges_dst[max_idx]
                
                # Remove edge
                edge_list = [(s, d) for s, d in edge_list if not (s == rm_u and d == rm_v)]
                edge_set.discard((rm_u, rm_v))
                
                if self.symmetric:
                    edge_list = [(s, d) for s, d in edge_list if not (s == rm_v and d == rm_u)]
                    edge_set.discard((rm_v, rm_u))
        
        # Create output graph
        if edge_list:
            src_final = torch.tensor([e[0] for e in edge_list], dtype=torch.long)
            dst_final = torch.tensor([e[1] for e in edge_list], dtype=torch.long)
            g_out = dgl.graph((src_final, dst_final), num_nodes=n_nodes)
        else:
            g_out = dgl.graph([], num_nodes=n_nodes)
        
        # Copy node features
        for key, value in g_in.ndata.items():
            g_out.ndata[key] = value.cpu()
        
        return g_out.to(self.device)


def sdrf_rewire_numba(
    g_in: dgl.DGLGraph,
    tau: float = 10.0,
    n_iterations: int = 200,
    c_plus: float = 30.0,
    symmetric: bool = True,
    device: str | torch.device = "cuda",
    verbose: bool = False,
    threads_per_block: int = 256
) -> dgl.DGLGraph:
    """
    Numba CUDA-optimized SDRF rewiring.
    
    This version uses custom CUDA kernels for:
    - Parallel triangle counting
    - Parallel square counting  
    - Vectorized curvature computation
    - Efficient candidate finding
    
    Parameters
    ----------
    g_in : dgl.DGLGraph
        Input graph.
    tau : float
        Softmax temperature.
    n_iterations : int
        Maximum iterations.
    c_plus : float
        Positive curvature threshold.
    symmetric : bool
        Keep graph undirected.
    device : str or torch.device
        Must be 'cuda' for Numba version.
    verbose : bool
        Print progress.
    threads_per_block : int
        CUDA threads per block.
        
    Returns
    -------
    dgl.DGLGraph
        Rewired graph.
    """
    optimizer = NumbaOptimizedSDRF(
        tau=tau,
        n_iterations=n_iterations,
        c_plus=c_plus,
        symmetric=symmetric,
        device=device,
        verbose=verbose,
        threads_per_block=threads_per_block
    )
    return optimizer.rewire(g_in)


# Additional optimization: Fused kernel for complete curvature computation
@cuda.jit
def fused_curvature_kernel(
    row_ptr: cuda.devicearray,
    col_idx: cuda.devicearray,
    degrees: cuda.devicearray,
    edges_src: cuda.devicearray,
    edges_dst: cuda.devicearray,
    curvatures: cuda.devicearray,
    n_edges: int
):
    """Fused kernel that computes triangles, squares, and curvature in one pass."""
    idx = grid(1)
    if idx >= n_edges:
        return
    
    u = edges_src[idx]
    v = edges_dst[idx]
    deg_u = degrees[u]
    deg_v = degrees[v]
    
    if deg_u <= 1 or deg_v <= 1:
        curvatures[idx] = 0.0
        return
    
    u_start = row_ptr[u]
    u_end = row_ptr[u + 1]
    v_start = row_ptr[v]
    v_end = row_ptr[v + 1]
    
    # Count triangles with two-pointer intersection
    triangles = 0
    i, j = u_start, v_start
    while i < u_end and j < v_end:
        if col_idx[i] == col_idx[j]:
            triangles += 1
            i += 1
            j += 1
        elif col_idx[i] < col_idx[j]:
            i += 1
        else:
            j += 1
    
    # Count squares - simplified version
    squares_u = 0
    squares_v = 0
    
    # For u's neighbors
    for i in range(u_start, u_end):
        k = col_idx[i]
        if k == v:
            continue
        
        # Check if k connects to any neighbor of v
        k_start = row_ptr[k]
        k_end = row_ptr[k + 1]
        
        # Binary search for any connection
        for j in range(v_start, v_end):
            l = col_idx[j]
            if l == u:
                continue
            
            # Binary search
            left, right = k_start, k_end - 1
            while left <= right:
                mid = (left + right) // 2
                if col_idx[mid] == l:
                    squares_u += 1
                    break
                elif col_idx[mid] < l:
                    left = mid + 1
                else:
                    right = mid - 1
    
    # Similar for v's neighbors (can be optimized further)
    # ... (similar code for squares_v)
    
    # Compute curvature
    deg_max = max(deg_u, deg_v)
    deg_min = min(deg_u, deg_v)
    gamma_max = max(max(squares_u, squares_v), 1)
    
    term_tri = (2.0 * triangles) / deg_max + triangles / deg_min
    term_sqr = (squares_u + squares_v) / (gamma_max * deg_max)
    
    curvatures[idx] = 2.0 / deg_u + 2.0 / deg_v - 2.0 + term_tri + term_sqr


# Memory pool for efficient GPU memory management
class CUDAMemoryPool:
    """Manages GPU memory allocation for repeated SDRF iterations."""
    
    def __init__(self, max_nodes: int, max_edges: int):
        self.max_nodes = max_nodes
        self.max_edges = max_edges
        
        # Pre-allocate arrays
        self.degrees = cuda.device_array(max_nodes, dtype=np.int32)
        self.triangles = cuda.device_array(max_edges, dtype=np.int32)
        self.squares_u = cuda.device_array(max_edges, dtype=np.int32)
        self.squares_v = cuda.device_array(max_edges, dtype=np.int32)
        self.curvatures = cuda.device_array(max_edges, dtype=np.float32)
        
    def get_arrays(self, n_nodes: int, n_edges: int):
        """Get pre-allocated arrays of the right size."""
        return (
            self.degrees[:n_nodes],
            self.triangles[:n_edges],
            self.squares_u[:n_edges],
            self.squares_v[:n_edges],
            self.curvatures[:n_edges]
        )
        



@dataclass
class GraphCharacteristics:
    """Characteristics of a graph for implementation selection."""
    n_nodes: int
    n_edges: int
    avg_degree: float
    density: float
    has_cuda: bool
    memory_available_gb: float
    
    @classmethod
    def from_graph(cls, g: dgl.DGLGraph) -> 'GraphCharacteristics':
        """Extract characteristics from a DGL graph."""
        n_nodes = g.num_nodes()
        n_edges = g.num_edges()
        avg_degree = n_edges / n_nodes if n_nodes > 0 else 0
        max_edges = n_nodes * (n_nodes - 1)  # Directed graph
        density = n_edges / max_edges if max_edges > 0 else 0
        
        has_cuda = torch.cuda.is_available()
        memory_gb = 0
        if has_cuda:
            props = torch.cuda.get_device_properties(0)
            memory_gb = props.total_memory / (1024**3)
        
        return cls(
            n_nodes=n_nodes,
            n_edges=n_edges,
            avg_degree=avg_degree,
            density=density,
            has_cuda=has_cuda,
            memory_available_gb=memory_gb
        )


class SDRFAutoSelector:
    """Automatically selects the best SDRF implementation based on graph characteristics."""
    
    def __init__(self, force_implementation: Optional[str] = None):
        """
        Parameters
        ----------
        force_implementation : str, optional
            Force a specific implementation: 'pytorch', 'numba', or None for auto
        """
        self.force_implementation = force_implementation
        
        # Performance model parameters (tuned from benchmarks)
        self.params = {
            'numba_setup_cost': 0.1,  # Fixed setup cost for Numba
            'numba_edge_cost': 1e-6,  # Cost per edge for Numba
            'pytorch_edge_cost': 2e-6,  # Cost per edge for PyTorch
            'memory_factor': 1.5,  # Memory usage multiplier for safety
        }
    
    def select_implementation(self, g: dgl.DGLGraph) -> Dict:
        """
        Select the best implementation for a given graph.
        
        Returns
        -------
        dict
            Contains 'function', 'name', and 'reason' for the selection
        """
        if self.force_implementation:
            if self.force_implementation == 'numba':
                return {
                    'function': sdrf_rewire_numba,
                    'name': 'Numba CUDA',
                    'reason': 'Forced by user'
                }
            else:
                return {
                    'function': sdrf_rewire_optimized,
                    'name': 'PyTorch Optimized',
                    'reason': 'Forced by user'
                }
        
        # Analyze graph
        chars = GraphCharacteristics.from_graph(g)
        
        # Decision logic
        if not chars.has_cuda:
            return {
                'function': sdrf_rewire_optimized,
                'name': 'PyTorch Optimized',
                'reason': 'No CUDA available (CPU-only)'
            }
        
        # Estimate memory usage (rough approximation)
        # CSR format: row_ptr (n+1) + col_idx (e) + edge arrays
        memory_needed_gb = (
            (chars.n_nodes * 4 +  # row_ptr
             chars.n_edges * 4 +  # col_idx
             chars.n_edges * 4 * 5)  # edge arrays (src, dst, tri, sq_u, sq_v)
        ) / (1024**3) * self.params['memory_factor']
        
        if memory_needed_gb > chars.memory_available_gb * 0.8:
            return {
                'function': sdrf_rewire_optimized,
                'name': 'PyTorch Optimized',
                'reason': f'Insufficient GPU memory (need {memory_needed_gb:.1f}GB)'
            }
        
        # Performance estimation
        numba_cost = (
            self.params['numba_setup_cost'] + 
            self.params['numba_edge_cost'] * chars.n_edges
        )
        pytorch_cost = self.params['pytorch_edge_cost'] * chars.n_edges
        
        # Special cases
        if chars.n_edges < 1000:
            return {
                'function': sdrf_rewire_optimized,
                'name': 'PyTorch Optimized',
                'reason': 'Small graph (Numba setup overhead not worth it)'
            }
        
        if chars.avg_degree > 100 and chars.n_nodes < 10000:
            return {
                'function': sdrf_rewire_numba,
                'name': 'Numba CUDA',
                'reason': 'Dense graph benefits from Numba kernels'
            }
        
        # General decision based on estimated cost
        if numba_cost < pytorch_cost:
            return {
                'function': sdrf_rewire_numba,
                'name': 'Numba CUDA',
                'reason': f'Estimated {pytorch_cost/numba_cost:.1f}x faster'
            }
        else:
            return {
                'function': sdrf_rewire_optimized,
                'name': 'PyTorch Optimized',
                'reason': f'Better for this graph size/structure'
            }
    
    def rewire(self, g: dgl.DGLGraph, **kwargs) -> dgl.DGLGraph:
        """
        Automatically select and apply the best SDRF implementation.
        
        Parameters
        ----------
        g : dgl.DGLGraph
            Input graph
        **kwargs
            Arguments passed to the SDRF implementation
            
        Returns
        -------
        dgl.DGLGraph
            Rewired graph
        """
        selection = self.select_implementation(g)
        
        # print(f"Selected implementation: {selection['name']}")
        # print(f"Reason: {selection['reason']}")
        
        return selection['function'](g, **kwargs)


def sdrf_rewire(
    g_in: dgl.DGLGraph,
    tau: float = 10.0,
    n_iterations: int = 200,
    c_plus: float = 30.0,
    symmetric: bool = True,
    device: str | torch.device = "cuda",
    verbose: bool = False,
    force_implementation: Optional[str] = 'numba'
) -> dgl.DGLGraph:
    """
    Automatically select and apply the best SDRF implementation.
    
    This function analyzes the input graph and chooses between:
    - PyTorch optimized: Best for most graphs, especially on CPU
    - Numba CUDA: Best for large dense graphs with available GPU memory
    
    Parameters
    ----------
    g_in : dgl.DGLGraph
        Input graph
    tau : float
        Softmax temperature
    n_iterations : int
        Maximum iterations
    c_plus : float
        Positive curvature threshold
    symmetric : bool
        Keep graph undirected
    device : str or torch.device
        Computation device
    verbose : bool
        Print progress
    force_implementation : str, optional
        Force specific implementation: 'pytorch' or 'numba'
        
    Returns
    -------
    dgl.DGLGraph
        Rewired graph
    """
    selector = SDRFAutoSelector(force_implementation)
    return selector.rewire(
        g_in,
        tau=tau,
        n_iterations=n_iterations,
        c_plus=c_plus,
        symmetric=symmetric,
        device=device,
        verbose=verbose
    )


# Example usage and testing
def demo_auto_selection():
    """Demonstrate automatic implementation selection."""
    print("SDRF Auto-Selection Demo")
    print("=" * 50)
    
    # Test different graph types
    test_graphs = [
        ("Small sparse", dgl.rand_graph(100, 300)),
        ("Medium sparse", dgl.rand_graph(5000, 15000)),
        ("Large sparse", dgl.rand_graph(50000, 150000)),
        ("Small dense", dgl.rand_graph(500, 20000)),
        ("Medium dense", dgl.rand_graph(2000, 100000)),
    ]
    
    selector = SDRFAutoSelector()
    
    for name, g in test_graphs:
        print(f"\n{name} graph (n={g.num_nodes()}, e={g.num_edges()})")
        chars = GraphCharacteristics.from_graph(g)
        print(f"  Average degree: {chars.avg_degree:.1f}")
        print(f"  Density: {chars.density:.4f}")
        
        selection = selector.select_implementation(g)
        print(f"  â†’ Selected: {selection['name']}")
        print(f"  â†’ Reason: {selection['reason']}")


# Performance predictor for user guidance
class SDRFPerformancePredictor:
    """Predicts SDRF performance and provides optimization suggestions."""
    
    def analyze_and_suggest(self, g: dgl.DGLGraph, target_time_seconds: float = 1.0):
        """
        Analyze graph and suggest parameters for target execution time.
        """
        chars = GraphCharacteristics.from_graph(g)
        
        # Estimate time per iteration (very rough)
        time_per_iter_pytorch = chars.n_edges * 5e-6
        time_per_iter_numba = 0.001 + chars.n_edges * 2e-6
        
        # Suggest iterations for target time
        suggested_iters_pytorch = int(target_time_seconds / time_per_iter_pytorch)
        suggested_iters_numba = int(target_time_seconds / time_per_iter_numba)
        
        print(f"\nPerformance Analysis for Graph:")
        print(f"  Nodes: {chars.n_nodes:,}")
        print(f"  Edges: {chars.n_edges:,}")
        print(f"  Avg Degree: {chars.avg_degree:.1f}")
        
        print(f"\nTo achieve ~{target_time_seconds}s execution time:")
        print(f"  PyTorch implementation: ~{suggested_iters_pytorch} iterations")
        print(f"  Numba implementation: ~{suggested_iters_numba} iterations")
        
        if chars.n_edges > 1e6:
            print("\nOptimization suggestions for large graph:")
            print("  - Consider sampling a subgraph first")
            print("  - Use fewer iterations (50-100)")
            print("  - Ensure sufficient GPU memory")
            print("  - Use batch processing if rewiring multiple graphs")
        
        return {
            'pytorch_iters': suggested_iters_pytorch,
            'numba_iters': suggested_iters_numba
        }

